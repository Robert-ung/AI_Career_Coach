{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ba2312",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "# ğŸ¯ Notebook 05 : Recommandation d'Offres d'Emploi\n",
    "\n",
    "**Objectif** : Matcher un CV avec toutes les offres et recommander les plus pertinentes\n",
    "\n",
    "**Pipeline** :\n",
    "1. Charger le CV et ses compÃ©tences extraites (Ã‰tape 2)\n",
    "2. Charger toutes les offres d'emploi (Ã‰tape 4)\n",
    "3. Utiliser le JobMatcher pour calculer les scores\n",
    "4. Trier et recommander les TOP offres\n",
    "\n",
    "**Modules utilisÃ©s** :\n",
    "- `src/cv_parser.py` : Parser de CV\n",
    "- `src/job_matcher.py` : SystÃ¨me de matching sÃ©mantique\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4f667669",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“ Projet : c:\\Users\\rober\\OneDrive\\Bureau\\PFE\n",
      "ğŸ“‚ Notebooks : c:\\Users\\rober\\OneDrive\\Bureau\\PFE\\notebooks\n",
      "âœ… JobMatcher importÃ© depuis src/job_matcher.py\n",
      "\n",
      "âœ… Imports terminÃ©s\n"
     ]
    }
   ],
   "source": [
    "# Imports\n",
    "import sys\n",
    "import json\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "from typing import List, Dict\n",
    "\n",
    "# Ajouter le dossier racine\n",
    "project_root = Path().absolute().parent\n",
    "sys.path.insert(0, str(project_root))\n",
    "\n",
    "print(f\"ğŸ“ Projet : {project_root}\")\n",
    "print(f\"ğŸ“‚ Notebooks : {Path().absolute()}\")\n",
    "\n",
    "# Importer nos modules custom\n",
    "try:\n",
    "    from src.job_matcher import JobMatcher, load_matcher\n",
    "    print(\"âœ… JobMatcher importÃ© depuis src/job_matcher.py\")\n",
    "except ImportError as e:\n",
    "    print(f\"âŒ Erreur d'import : {e}\")\n",
    "    print(\"âš ï¸  VÃ©rifiez que src/job_matcher.py existe\")\n",
    "\n",
    "print(\"\\nâœ… Imports terminÃ©s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0359693e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… CompÃ©tences CV chargÃ©es\n",
      "   â€¢ Fichier : RESUME ROBERT UNG.pdf\n",
      "   â€¢ Date extraction : 2026-01-25\n",
      "   â€¢ CompÃ©tences techniques : 24\n",
      "   â€¢ Soft skills : 5\n",
      "\n",
      "ğŸ“‹ Exemples de compÃ©tences :\n",
      "   â€¢ .net\n",
      "   â€¢ artificial intelligence\n",
      "   â€¢ big data\n",
      "   â€¢ c\n",
      "   â€¢ c#\n",
      "   â€¢ c++\n",
      "   â€¢ data analysis\n",
      "   â€¢ data science\n",
      "   â€¢ deep learning\n",
      "   â€¢ docker\n"
     ]
    }
   ],
   "source": [
    "# Charger les compÃ©tences extraites du CV (Ã‰tape 2)\n",
    "skills_path = project_root / \"outputs\" / \"extracted_skills_simple.json\"\n",
    "\n",
    "if not skills_path.exists():\n",
    "    print(\"âŒ Fichier compÃ©tences non trouvÃ©\")\n",
    "    print(f\"âš ï¸  Chemin attendu : {skills_path}\")\n",
    "    print(\"âš ï¸  ExÃ©cutez d'abord 02_skills_extraction_simple.ipynb\")\n",
    "    cv_skills = []\n",
    "else:\n",
    "    with open(skills_path, 'r', encoding='utf-8') as f:\n",
    "        cv_data = json.load(f)\n",
    "    \n",
    "    cv_skills = cv_data['technical_skills']\n",
    "    cv_soft_skills = cv_data.get('soft_skills', [])\n",
    "    \n",
    "    print(f\"âœ… CompÃ©tences CV chargÃ©es\")\n",
    "    print(f\"   â€¢ Fichier : {cv_data.get('cv_file', 'N/A')}\")\n",
    "    print(f\"   â€¢ Date extraction : {cv_data.get('extraction_date', 'N/A')}\")\n",
    "    print(f\"   â€¢ CompÃ©tences techniques : {len(cv_skills)}\")\n",
    "    print(f\"   â€¢ Soft skills : {len(cv_soft_skills)}\")\n",
    "    print(f\"\\nğŸ“‹ Exemples de compÃ©tences :\")\n",
    "    for skill in cv_skills[:10]:\n",
    "        print(f\"   â€¢ {skill}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "47fcf046",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Offres d'emploi chargÃ©es\n",
      "   â€¢ Fichier : jobs_dataset.json\n",
      "   â€¢ Total offres : 25\n",
      "   â€¢ GÃ©nÃ©rÃ© le : 2026-01-25 18:21:43\n",
      "   â€¢ CatÃ©gories : ml_engineer, data_scientist, python_developer, devops_engineer, frontend_developer\n",
      "\n",
      "ğŸ“Š RÃ©partition par catÃ©gorie :\n",
      "   â€¢ ml_engineer          : 5 offres\n",
      "   â€¢ data_scientist       : 5 offres\n",
      "   â€¢ python_developer     : 5 offres\n",
      "   â€¢ devops_engineer      : 5 offres\n",
      "   â€¢ frontend_developer   : 5 offres\n"
     ]
    }
   ],
   "source": [
    "# Charger toutes les offres d'emploi (Ã‰tape 4)\n",
    "jobs_dir = project_root / \"data\" / \"jobs\"\n",
    "all_jobs = []\n",
    "\n",
    "if not jobs_dir.exists():\n",
    "    print(f\"âŒ Dossier jobs/ non trouvÃ© : {jobs_dir}\")\n",
    "    print(\"âš ï¸  ExÃ©cutez d'abord 04_job_generation.ipynb\")\n",
    "else:\n",
    "    # Charger le dataset complet\n",
    "    dataset_path = jobs_dir / \"jobs_dataset.json\"\n",
    "    \n",
    "    if dataset_path.exists():\n",
    "        with open(dataset_path, 'r', encoding='utf-8') as f:\n",
    "            dataset = json.load(f)\n",
    "        \n",
    "        all_jobs = dataset['jobs']\n",
    "        metadata = dataset['metadata']\n",
    "        \n",
    "        print(f\"âœ… Offres d'emploi chargÃ©es\")\n",
    "        print(f\"   â€¢ Fichier : {dataset_path.name}\")\n",
    "        print(f\"   â€¢ Total offres : {metadata['total_jobs']}\")\n",
    "        print(f\"   â€¢ GÃ©nÃ©rÃ© le : {metadata['generated_date']}\")\n",
    "        print(f\"   â€¢ CatÃ©gories : {', '.join(metadata['categories'])}\")\n",
    "        \n",
    "        # Statistiques par catÃ©gorie\n",
    "        print(f\"\\nğŸ“Š RÃ©partition par catÃ©gorie :\")\n",
    "        for category in metadata['categories']:\n",
    "            count = len([j for j in all_jobs if j['category'] == category])\n",
    "            print(f\"   â€¢ {category:20s} : {count} offres\")\n",
    "    else:\n",
    "        print(f\"âŒ Fichier {dataset_path.name} non trouvÃ©\")\n",
    "        print(\"âš ï¸  ExÃ©cutez 04_job_generation.ipynb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3e6cbe4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ” Initialisation du JobMatcher...\n",
      "â³ Chargement du modÃ¨le all-mpnet-base-v2 (premiÃ¨re fois : ~420 MB)\n",
      "ğŸ” Chargement du modÃ¨le all-mpnet-base-v2...\n",
      "âœ… ModÃ¨le chargÃ©\n",
      "âœ… JobMatcher initialisÃ©\n",
      "   â€¢ ModÃ¨le : all-mpnet-base-v2\n",
      "   â€¢ Dimension embeddings : 768\n"
     ]
    }
   ],
   "source": [
    "# Charger le modÃ¨le de matching sÃ©mantique\n",
    "print(\"\\nğŸ” Initialisation du JobMatcher...\")\n",
    "print(\"â³ Chargement du modÃ¨le all-mpnet-base-v2 (premiÃ¨re fois : ~420 MB)\")\n",
    "\n",
    "try:\n",
    "    matcher = load_matcher(model_name='all-mpnet-base-v2')\n",
    "    print(f\"âœ… JobMatcher initialisÃ©\")\n",
    "    print(f\"   â€¢ ModÃ¨le : {matcher.model_name}\")\n",
    "    print(f\"   â€¢ Dimension embeddings : 768\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Erreur : {e}\")\n",
    "    matcher = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "28d94f58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ” Calcul des scores de matching...\n",
      "â³ Analyse de 25 offres avec 24 compÃ©tences...\n",
      "   (Temps estimÃ© : 30-60 secondes)\n",
      "\n",
      "âœ… Analyse terminÃ©e !\n",
      "   â€¢ 25 offres scorÃ©es\n",
      "   â€¢ Meilleur score : 66.7%\n",
      "   â€¢ Score moyen : 52.3%\n",
      "   â€¢ Pire score : 40.9%\n"
     ]
    }
   ],
   "source": [
    "# Calculer le score pour chaque offre avec le JobMatcher\n",
    "if not cv_skills:\n",
    "    print(\"âŒ Aucune compÃ©tence CV chargÃ©e\")\n",
    "elif not all_jobs:\n",
    "    print(\"âŒ Aucune offre chargÃ©e\")\n",
    "elif matcher is None:\n",
    "    print(\"âŒ JobMatcher non initialisÃ©\")\n",
    "else:\n",
    "    print(\"\\nğŸ” Calcul des scores de matching...\")\n",
    "    print(f\"â³ Analyse de {len(all_jobs)} offres avec {len(cv_skills)} compÃ©tences...\")\n",
    "    print(\"   (Temps estimÃ© : 30-60 secondes)\\n\")\n",
    "    \n",
    "    # Utiliser la mÃ©thode rank_jobs du JobMatcher\n",
    "    recommendations = matcher.rank_jobs(cv_skills, all_jobs)\n",
    "    \n",
    "    print(f\"âœ… Analyse terminÃ©e !\")\n",
    "    print(f\"   â€¢ {len(recommendations)} offres scorÃ©es\")\n",
    "    print(f\"   â€¢ Meilleur score : {recommendations[0]['global_score']:.1f}%\")\n",
    "    print(f\"   â€¢ Score moyen : {sum(r['global_score'] for r in recommendations) / len(recommendations):.1f}%\")\n",
    "    print(f\"   â€¢ Pire score : {recommendations[-1]['global_score']:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "483d4ccd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ğŸ† TOP 10 OFFRES RECOMMANDÃ‰ES\n",
      "======================================================================\n",
      "\n",
      "ğŸŸ¡ #1 - Data Scientist Junior (BON MATCH)\n",
      "----------------------------------------------------------------------\n",
      "   ğŸ¢ Entreprise      : Analytics Pro\n",
      "   ğŸ“ Localisation    : Nantes, France ğŸ  (Remote)\n",
      "   ğŸ’¼ Type            : CDI | ExpÃ©rience : 0-2 ans\n",
      "   ğŸ’° Salaire         : 35-45Kâ‚¬\n",
      "   ğŸ‘¥ Candidats       : 116\n",
      "\n",
      "   ğŸ“Š SCORES DÃ‰TAILLÃ‰S :\n",
      "      â€¢ Global       : 66.7% â­\n",
      "      â€¢ CompÃ©tences  : 45.4%\n",
      "      â€¢ ExpÃ©rience   : 100%\n",
      "      â€¢ Localisation : 100%\n",
      "      â€¢ CompÃ©tition  : 40%\n",
      "\n",
      "   ğŸ¯ TOP COMPÃ‰TENCES MATCHÃ‰ES :\n",
      "      âœ“ scikit-learn\n",
      "      âœ“ matplotlib\n",
      "      âœ“ jupyter\n",
      "      âœ“ numpy\n",
      "      âœ“ data analysis\n",
      "\n",
      "   ğŸ”§ CompÃ©tences requises (extrait) :\n",
      "      â€¢ Python (pandas, numpy, matplotlib)\n",
      "      â€¢ Machine Learning (scikit-learn)\n",
      "      â€¢ SQL\n",
      "\n",
      "   ğŸ”— Postuler : https://example-jobs.com/6\n",
      "\n",
      "ğŸŸ¡ #2 - Python Developer Junior (BON MATCH)\n",
      "----------------------------------------------------------------------\n",
      "   ğŸ¢ Entreprise      : WebDev Studio\n",
      "   ğŸ“ Localisation    : Toulouse, France ğŸ  (Remote)\n",
      "   ğŸ’¼ Type            : CDI | ExpÃ©rience : 0-2 ans\n",
      "   ğŸ’° Salaire         : 32-42Kâ‚¬\n",
      "   ğŸ‘¥ Candidats       : 62\n",
      "\n",
      "   ğŸ“Š SCORES DÃ‰TAILLÃ‰S :\n",
      "      â€¢ Global       : 64.4% â­\n",
      "      â€¢ CompÃ©tences  : 34.8%\n",
      "      â€¢ ExpÃ©rience   : 100%\n",
      "      â€¢ Localisation : 100%\n",
      "      â€¢ CompÃ©tition  : 70%\n",
      "\n",
      "   ğŸ¯ TOP COMPÃ‰TENCES MATCHÃ‰ES :\n",
      "      âœ“ python\n",
      "      âœ“ sql\n",
      "      âœ“ scikit-learn\n",
      "      âœ“ jupyter\n",
      "      âœ“ numpy\n",
      "\n",
      "   ğŸ”§ CompÃ©tences requises (extrait) :\n",
      "      â€¢ Python (bonnes pratiques)\n",
      "      â€¢ APIs RESTful\n",
      "      â€¢ SQL\n",
      "\n",
      "   ğŸ”— Postuler : https://example-jobs.com/11\n",
      "\n",
      "ğŸŸ¡ #3 - Junior ML Engineer (BON MATCH)\n",
      "----------------------------------------------------------------------\n",
      "   ğŸ¢ Entreprise      : AI Startup Paris\n",
      "   ğŸ“ Localisation    : Toulouse, France \n",
      "   ğŸ’¼ Type            : CDI | ExpÃ©rience : 0-2 ans\n",
      "   ğŸ’° Salaire         : 35-45Kâ‚¬\n",
      "   ğŸ‘¥ Candidats       : 99\n",
      "\n",
      "   ğŸ“Š SCORES DÃ‰TAILLÃ‰S :\n",
      "      â€¢ Global       : 61.2% â­\n",
      "      â€¢ CompÃ©tences  : 40.4%\n",
      "      â€¢ ExpÃ©rience   : 100%\n",
      "      â€¢ Localisation : 80%\n",
      "      â€¢ CompÃ©tition  : 40%\n",
      "\n",
      "   ğŸ¯ TOP COMPÃ‰TENCES MATCHÃ‰ES :\n",
      "      âœ“ scikit-learn\n",
      "      âœ“ docker\n",
      "      âœ“ machine learning\n",
      "      âœ“ git\n",
      "      âœ“ sql\n",
      "\n",
      "   ğŸ”§ CompÃ©tences requises (extrait) :\n",
      "      â€¢ Python (numpy, pandas, scikit-learn)\n",
      "      â€¢ Machine Learning basics (supervised learning)\n",
      "      â€¢ Git et GitHub\n",
      "\n",
      "   ğŸ”— Postuler : https://example-jobs.com/1\n",
      "\n",
      "ğŸŸ¡ #4 - Data Scientist - Marketing (BON MATCH)\n",
      "----------------------------------------------------------------------\n",
      "   ğŸ¢ Entreprise      : MarketingTech\n",
      "   ğŸ“ Localisation    : Toulouse, France \n",
      "   ğŸ’¼ Type            : CDI | ExpÃ©rience : 1-3 ans\n",
      "   ğŸ’° Salaire         : 40-50Kâ‚¬\n",
      "   ğŸ‘¥ Candidats       : 25\n",
      "\n",
      "   ğŸ“Š SCORES DÃ‰TAILLÃ‰S :\n",
      "      â€¢ Global       : 58.3% â­\n",
      "      â€¢ CompÃ©tences  : 35.1%\n",
      "      â€¢ ExpÃ©rience   : 75%\n",
      "      â€¢ Localisation : 80%\n",
      "      â€¢ CompÃ©tition  : 100%\n",
      "\n",
      "   ğŸ¯ TOP COMPÃ‰TENCES MATCHÃ‰ES :\n",
      "      âœ“ scikit-learn\n",
      "      âœ“ sql\n",
      "      âœ“ python\n",
      "      âœ“ data analysis\n",
      "      âœ“ matplotlib\n",
      "\n",
      "   ğŸ”§ CompÃ©tences requises (extrait) :\n",
      "      â€¢ Python et/ou R\n",
      "      â€¢ Machine Learning (classification, clustering)\n",
      "      â€¢ SQL avancÃ©\n",
      "\n",
      "   ğŸ”— Postuler : https://example-jobs.com/7\n",
      "\n",
      "ğŸŸ¡ #5 - Data Scientist - Finance (BON MATCH)\n",
      "----------------------------------------------------------------------\n",
      "   ğŸ¢ Entreprise      : FinTech Solutions\n",
      "   ğŸ“ Localisation    : Toulouse, France \n",
      "   ğŸ’¼ Type            : CDI | ExpÃ©rience : 2-4 ans\n",
      "   ğŸ’° Salaire         : 45-60Kâ‚¬\n",
      "   ğŸ‘¥ Candidats       : 56\n",
      "\n",
      "   ğŸ“Š SCORES DÃ‰TAILLÃ‰S :\n",
      "      â€¢ Global       : 58.3% â­\n",
      "      â€¢ CompÃ©tences  : 41.1%\n",
      "      â€¢ ExpÃ©rience   : 75%\n",
      "      â€¢ Localisation : 80%\n",
      "      â€¢ CompÃ©tition  : 70%\n",
      "\n",
      "   ğŸ¯ TOP COMPÃ‰TENCES MATCHÃ‰ES :\n",
      "      âœ“ scikit-learn\n",
      "      âœ“ docker\n",
      "      âœ“ git\n",
      "      âœ“ sql\n",
      "      âœ“ machine learning\n",
      "\n",
      "   ğŸ”§ CompÃ©tences requises (extrait) :\n",
      "      â€¢ Machine Learning (classification, regression)\n",
      "      â€¢ Time series analysis\n",
      "      â€¢ Python (pandas, scikit-learn)\n",
      "\n",
      "   ğŸ”— Postuler : https://example-jobs.com/8\n",
      "\n",
      "ğŸŸ¡ #6 - ML Engineer - Computer Vision (BON MATCH)\n",
      "----------------------------------------------------------------------\n",
      "   ğŸ¢ Entreprise      : VisionTech\n",
      "   ğŸ“ Localisation    : Paris (Hybrid) ğŸ  (Remote)\n",
      "   ğŸ’¼ Type            : CDI | ExpÃ©rience : 1-3 ans\n",
      "   ğŸ’° Salaire         : 40-50Kâ‚¬\n",
      "   ğŸ‘¥ Candidats       : 72\n",
      "\n",
      "   ğŸ“Š SCORES DÃ‰TAILLÃ‰S :\n",
      "      â€¢ Global       : 58.2% â­\n",
      "      â€¢ CompÃ©tences  : 34.9%\n",
      "      â€¢ ExpÃ©rience   : 75%\n",
      "      â€¢ Localisation : 100%\n",
      "      â€¢ CompÃ©tition  : 70%\n",
      "\n",
      "   ğŸ¯ TOP COMPÃ‰TENCES MATCHÃ‰ES :\n",
      "      âœ“ docker\n",
      "      âœ“ data science\n",
      "      âœ“ deep learning\n",
      "      âœ“ java\n",
      "      âœ“ data analysis\n",
      "\n",
      "   ğŸ”§ CompÃ©tences requises (extrait) :\n",
      "      â€¢ Deep Learning (CNNs, architectures modernes)\n",
      "      â€¢ PyTorch ou TensorFlow\n",
      "      â€¢ Computer Vision (OpenCV, PIL)\n",
      "\n",
      "   ğŸ”— Postuler : https://example-jobs.com/2\n",
      "\n",
      "ğŸŸ¡ #7 - Frontend Developer Junior (BON MATCH)\n",
      "----------------------------------------------------------------------\n",
      "   ğŸ¢ Entreprise      : WebAgency\n",
      "   ğŸ“ Localisation    : Paris (Hybrid) ğŸ  (Remote)\n",
      "   ğŸ’¼ Type            : CDI | ExpÃ©rience : 0-2 ans\n",
      "   ğŸ’° Salaire         : 30-40Kâ‚¬\n",
      "   ğŸ‘¥ Candidats       : 69\n",
      "\n",
      "   ğŸ“Š SCORES DÃ‰TAILLÃ‰S :\n",
      "      â€¢ Global       : 57.1% â­\n",
      "      â€¢ CompÃ©tences  : 20.1%\n",
      "      â€¢ ExpÃ©rience   : 100%\n",
      "      â€¢ Localisation : 100%\n",
      "      â€¢ CompÃ©tition  : 70%\n",
      "\n",
      "   ğŸ¯ TOP COMPÃ‰TENCES MATCHÃ‰ES :\n",
      "      âœ“ node.js\n",
      "      âœ“ java\n",
      "      âœ“ data analysis\n",
      "      âœ“ c#\n",
      "      âœ“ git\n",
      "\n",
      "   ğŸ”§ CompÃ©tences requises (extrait) :\n",
      "      â€¢ React basics\n",
      "      â€¢ JavaScript (ES6+)\n",
      "      â€¢ HTML5, CSS3\n",
      "\n",
      "   ğŸ”— Postuler : https://example-jobs.com/21\n",
      "\n",
      "ğŸŸ¡ #8 - Python Developer - Data Engineering (BON MATCH)\n",
      "----------------------------------------------------------------------\n",
      "   ğŸ¢ Entreprise      : BigData Corp\n",
      "   ğŸ“ Localisation    : Bordeaux, France ğŸ  (Remote)\n",
      "   ğŸ’¼ Type            : CDI | ExpÃ©rience : 2-4 ans\n",
      "   ğŸ’° Salaire         : 42-55Kâ‚¬\n",
      "   ğŸ‘¥ Candidats       : 96\n",
      "\n",
      "   ğŸ“Š SCORES DÃ‰TAILLÃ‰S :\n",
      "      â€¢ Global       : 54.9% â­\n",
      "      â€¢ CompÃ©tences  : 34.2%\n",
      "      â€¢ ExpÃ©rience   : 75%\n",
      "      â€¢ Localisation : 100%\n",
      "      â€¢ CompÃ©tition  : 40%\n",
      "\n",
      "   ğŸ¯ TOP COMPÃ‰TENCES MATCHÃ‰ES :\n",
      "      âœ“ docker\n",
      "      âœ“ python\n",
      "      âœ“ pandas\n",
      "      âœ“ matplotlib\n",
      "      âœ“ numpy\n",
      "\n",
      "   ğŸ”§ CompÃ©tences requises (extrait) :\n",
      "      â€¢ Python (pandas, numpy)\n",
      "      â€¢ ETL et data pipelines\n",
      "      â€¢ SQL avancÃ©\n",
      "\n",
      "   ğŸ”— Postuler : https://example-jobs.com/13\n",
      "\n",
      "ğŸŸ¡ #9 - DevOps Engineer - Kubernetes (BON MATCH)\n",
      "----------------------------------------------------------------------\n",
      "   ğŸ¢ Entreprise      : ContainerTech\n",
      "   ğŸ“ Localisation    : Nantes, France ğŸ  (Remote)\n",
      "   ğŸ’¼ Type            : CDI | ExpÃ©rience : 2-4 ans\n",
      "   ğŸ’° Salaire         : 45-55Kâ‚¬\n",
      "   ğŸ‘¥ Candidats       : 7\n",
      "\n",
      "   ğŸ“Š SCORES DÃ‰TAILLÃ‰S :\n",
      "      â€¢ Global       : 54.4% â­\n",
      "      â€¢ CompÃ©tences  : 21.2%\n",
      "      â€¢ ExpÃ©rience   : 75%\n",
      "      â€¢ Localisation : 100%\n",
      "      â€¢ CompÃ©tition  : 100%\n",
      "\n",
      "   ğŸ¯ TOP COMPÃ‰TENCES MATCHÃ‰ES :\n",
      "      âœ“ docker\n",
      "      âœ“ data analysis\n",
      "      âœ“ linux\n",
      "      âœ“ c\n",
      "      âœ“ data science\n",
      "\n",
      "   ğŸ”§ CompÃ©tences requises (extrait) :\n",
      "      â€¢ Kubernetes (dÃ©ploiements, services, ingress)\n",
      "      â€¢ Docker avancÃ©\n",
      "      â€¢ Terraform ou Ansible\n",
      "\n",
      "   ğŸ”— Postuler : https://example-jobs.com/17\n",
      "\n",
      "ğŸŸ¡ #10 - Data Scientist - HealthTech (BON MATCH)\n",
      "----------------------------------------------------------------------\n",
      "   ğŸ¢ Entreprise      : MedAI\n",
      "   ğŸ“ Localisation    : Toulouse, France \n",
      "   ğŸ’¼ Type            : CDI | ExpÃ©rience : 2-4 ans\n",
      "   ğŸ’° Salaire         : 48-58Kâ‚¬\n",
      "   ğŸ‘¥ Candidats       : 134\n",
      "\n",
      "   ğŸ“Š SCORES DÃ‰TAILLÃ‰S :\n",
      "      â€¢ Global       : 54.3% â­\n",
      "      â€¢ CompÃ©tences  : 39.2%\n",
      "      â€¢ ExpÃ©rience   : 75%\n",
      "      â€¢ Localisation : 80%\n",
      "      â€¢ CompÃ©tition  : 40%\n",
      "\n",
      "   ğŸ¯ TOP COMPÃ‰TENCES MATCHÃ‰ES :\n",
      "      âœ“ scikit-learn\n",
      "      âœ“ sql\n",
      "      âœ“ machine learning\n",
      "      âœ“ data science\n",
      "      âœ“ python\n",
      "\n",
      "   ğŸ”§ CompÃ©tences requises (extrait) :\n",
      "      â€¢ Machine Learning et/ou Deep Learning\n",
      "      â€¢ Python avancÃ©\n",
      "      â€¢ Statistiques\n",
      "\n",
      "   ğŸ”— Postuler : https://example-jobs.com/10\n"
     ]
    }
   ],
   "source": [
    "# Afficher les 10 meilleures recommandations\n",
    "if 'recommendations' in locals() and recommendations:\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"ğŸ† TOP 10 OFFRES RECOMMANDÃ‰ES\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    for i, job in enumerate(recommendations[:10], 1):\n",
    "        # Emoji selon le score\n",
    "        if job['global_score'] >= 70:\n",
    "            emoji = \"ğŸŸ¢\"\n",
    "            label = \"EXCELLENT MATCH\"\n",
    "        elif job['global_score'] >= 50:\n",
    "            emoji = \"ğŸŸ¡\"\n",
    "            label = \"BON MATCH\"\n",
    "        elif job['global_score'] >= 40:\n",
    "            emoji = \"ğŸŸ \"\n",
    "            label = \"MATCH MOYEN\"\n",
    "        else:\n",
    "            emoji = \"ğŸ”´\"\n",
    "            label = \"MATCH FAIBLE\"\n",
    "        \n",
    "        print(f\"\\n{emoji} #{i} - {job['title']} ({label})\")\n",
    "        print(\"-\" * 70)\n",
    "        print(f\"   ğŸ¢ Entreprise      : {job['company']}\")\n",
    "        print(f\"   ğŸ“ Localisation    : {job['location']} {'ğŸ  (Remote)' if job['remote_ok'] else ''}\")\n",
    "        print(f\"   ğŸ’¼ Type            : {job['type']} | ExpÃ©rience : {job['experience']}\")\n",
    "        print(f\"   ğŸ’° Salaire         : {job['salary']}\")\n",
    "        print(f\"   ğŸ‘¥ Candidats       : {job['applicants']}\")\n",
    "        \n",
    "        print(f\"\\n   ğŸ“Š SCORES DÃ‰TAILLÃ‰S :\")\n",
    "        print(f\"      â€¢ Global       : {job['global_score']:.1f}% â­\")\n",
    "        print(f\"      â€¢ CompÃ©tences  : {job['skills_score']:.1f}%\")\n",
    "        print(f\"      â€¢ ExpÃ©rience   : {job['experience_score']}%\")\n",
    "        print(f\"      â€¢ Localisation : {job['location_score']}%\")\n",
    "        print(f\"      â€¢ CompÃ©tition  : {job['competition_score']}%\")\n",
    "        \n",
    "        print(f\"\\n   ğŸ¯ TOP COMPÃ‰TENCES MATCHÃ‰ES :\")\n",
    "        for skill in job['skills_details']['top_skills']:\n",
    "            print(f\"      âœ“ {skill}\")\n",
    "        \n",
    "        print(f\"\\n   ğŸ”§ CompÃ©tences requises (extrait) :\")\n",
    "        for req in job['requirements'][:3]:\n",
    "            print(f\"      â€¢ {req}\")\n",
    "        \n",
    "        print(f\"\\n   ğŸ”— Postuler : {job['url']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4112abf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ğŸ“Š STATISTIQUES DES RECOMMANDATIONS\n",
      "======================================================================\n",
      "\n",
      "ğŸ¯ Distribution des matches :\n",
      "   â€¢ Excellent match (â‰¥70%)  :  0 offres ğŸŸ¢\n",
      "   â€¢ Bon match (50-70%)      : 16 offres ğŸŸ¡\n",
      "   â€¢ Match moyen (40-50%)    :  9 offres ğŸŸ \n",
      "   â€¢ Match faible (<40%)     :  0 offres ğŸ”´\n",
      "\n",
      "ğŸ“‚ Score moyen par catÃ©gorie :\n",
      "   â€¢ data_scientist            :  56.8% â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "   â€¢ python_developer          :  54.4% â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "   â€¢ ml_engineer               :  52.5% â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "   â€¢ devops_engineer           :  49.0% â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "   â€¢ frontend_developer        :  48.8% â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ\n",
      "\n",
      "ğŸ  Remote vs On-site :\n",
      "   â€¢ Offres remote  ( 8) : 56.6% ğŸ \n",
      "   â€¢ Offres on-site (17) : 50.3% ğŸ¢\n",
      "\n",
      "ğŸ’¼ Recommandations par niveau :\n",
      "   â€¢ 2-4 ans         :  8 offres | Score moyen : 52.6%\n",
      "   â€¢ 0-2 ans         :  5 offres | Score moyen : 60.6%\n",
      "   â€¢ 1-3 ans         :  5 offres | Score moyen : 53.0%\n",
      "   â€¢ 3-5 ans         :  4 offres | Score moyen : 45.0%\n",
      "   â€¢ 4-6 ans         :  2 offres | Score moyen : 46.0%\n",
      "   â€¢ 5-7 ans         :  1 offres | Score moyen : 46.2%\n"
     ]
    }
   ],
   "source": [
    "# Statistiques sur les recommandations\n",
    "if 'recommendations' in locals() and recommendations:\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"ğŸ“Š STATISTIQUES DES RECOMMANDATIONS\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Distribution des scores\n",
    "    excellent_match = [j for j in recommendations if j['global_score'] >= 70]\n",
    "    good_match = [j for j in recommendations if 50 <= j['global_score'] < 70]\n",
    "    medium_match = [j for j in recommendations if 40 <= j['global_score'] < 50]\n",
    "    low_match = [j for j in recommendations if j['global_score'] < 40]\n",
    "    \n",
    "    print(f\"\\nğŸ¯ Distribution des matches :\")\n",
    "    print(f\"   â€¢ Excellent match (â‰¥70%)  : {len(excellent_match):2d} offres ğŸŸ¢\")\n",
    "    print(f\"   â€¢ Bon match (50-70%)      : {len(good_match):2d} offres ğŸŸ¡\")\n",
    "    print(f\"   â€¢ Match moyen (40-50%)    : {len(medium_match):2d} offres ğŸŸ \")\n",
    "    print(f\"   â€¢ Match faible (<40%)     : {len(low_match):2d} offres ğŸ”´\")\n",
    "    \n",
    "    # Score moyen par catÃ©gorie\n",
    "    print(f\"\\nğŸ“‚ Score moyen par catÃ©gorie :\")\n",
    "    categories = set(job.get('category', 'unknown') for job in all_jobs)\n",
    "    \n",
    "    category_scores = {}\n",
    "    for category in categories:\n",
    "        cat_jobs = [r for r in recommendations \n",
    "                    if any(j['job_id'] == r['job_id'] and j.get('category') == category \n",
    "                          for j in all_jobs)]\n",
    "        \n",
    "        if cat_jobs:\n",
    "            avg_score = sum(j['global_score'] for j in cat_jobs) / len(cat_jobs)\n",
    "            category_scores[category] = avg_score\n",
    "    \n",
    "    # Trier par score dÃ©croissant\n",
    "    for category, avg_score in sorted(category_scores.items(), key=lambda x: x[1], reverse=True):\n",
    "        bar_length = int(avg_score / 5)\n",
    "        bar = \"â–ˆ\" * bar_length\n",
    "        print(f\"   â€¢ {category:25s} : {avg_score:5.1f}% {bar}\")\n",
    "    \n",
    "    # Remote vs On-site\n",
    "    remote_jobs = [j for j in recommendations if j['remote_ok']]\n",
    "    onsite_jobs = [j for j in recommendations if not j['remote_ok']]\n",
    "    \n",
    "    print(f\"\\nğŸ  Remote vs On-site :\")\n",
    "    if remote_jobs:\n",
    "        avg_remote = sum(j['global_score'] for j in remote_jobs) / len(remote_jobs)\n",
    "        print(f\"   â€¢ Offres remote  ({len(remote_jobs):2d}) : {avg_remote:.1f}% ğŸ \")\n",
    "    \n",
    "    if onsite_jobs:\n",
    "        avg_onsite = sum(j['global_score'] for j in onsite_jobs) / len(onsite_jobs)\n",
    "        print(f\"   â€¢ Offres on-site ({len(onsite_jobs):2d}) : {avg_onsite:.1f}% ğŸ¢\")\n",
    "    \n",
    "    # Offres par niveau d'expÃ©rience\n",
    "    print(f\"\\nğŸ’¼ Recommandations par niveau :\")\n",
    "    exp_levels = {}\n",
    "    for job in recommendations:\n",
    "        exp = job['experience']\n",
    "        if exp not in exp_levels:\n",
    "            exp_levels[exp] = {'count': 0, 'avg_score': 0}\n",
    "        exp_levels[exp]['count'] += 1\n",
    "        exp_levels[exp]['avg_score'] += job['global_score']\n",
    "    \n",
    "    for exp, data in sorted(exp_levels.items(), key=lambda x: x[1]['avg_score'], reverse=True):\n",
    "        avg = data['avg_score'] / data['count']\n",
    "        print(f\"   â€¢ {exp:15s} : {data['count']:2d} offres | Score moyen : {avg:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a23deb8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ğŸ”§ COMPÃ‰TENCES LES PLUS DEMANDÃ‰ES (TOP offres)\n",
      "======================================================================\n",
      "\n",
      "ğŸ“‹ TOP 15 compÃ©tences recherchÃ©es :\n",
      "   â€¢ SQL                                      : â–ˆâ–ˆâ–ˆ (3)\n",
      "   â€¢ Statistiques                             : â–ˆâ–ˆ (2)\n",
      "   â€¢ Git                                      : â–ˆâ–ˆ (2)\n",
      "   â€¢ SQL avancÃ©                               : â–ˆâ–ˆ (2)\n",
      "   â€¢ Python avancÃ©                            : â–ˆâ–ˆ (2)\n",
      "   â€¢ Python (pandas, numpy, matplotlib)       : â–ˆ (1)\n",
      "   â€¢ Machine Learning (scikit-learn)          : â–ˆ (1)\n",
      "   â€¢ Communication (prÃ©sentation de rÃ©sultats) : â–ˆ (1)\n",
      "   â€¢ Python (bonnes pratiques)                : â–ˆ (1)\n",
      "   â€¢ APIs RESTful                             : â–ˆ (1)\n",
      "   â€¢ Tests unitaires (pytest)                 : â–ˆ (1)\n",
      "   â€¢ Python (numpy, pandas, scikit-learn)     : â–ˆ (1)\n",
      "   â€¢ Machine Learning basics (supervised learning) : â–ˆ (1)\n",
      "   â€¢ Git et GitHub                            : â–ˆ (1)\n",
      "   â€¢ Docker (notions de base)                 : â–ˆ (1)\n",
      "\n",
      "âš ï¸  CompÃ©tences Ã  dÃ©velopper (prÃ©sentes dans les TOP offres) :\n",
      "   â€¢ APIs RESTful\n",
      "   â€¢ Airflow\n",
      "   â€¢ ETL et data pipelines\n",
      "   â€¢ Monitoring (Prometheus)\n",
      "   â€¢ Responsive design\n",
      "   â€¢ Statistiques\n",
      "   â€¢ Statistiques et A/B testing\n",
      "   â€¢ Terraform ou Ansible\n",
      "   â€¢ Tests unitaires (pytest)\n",
      "   â€¢ Time series analysis\n"
     ]
    }
   ],
   "source": [
    "# Analyser les compÃ©tences les plus demandÃ©es\n",
    "if 'recommendations' in locals() and recommendations:\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"ğŸ”§ COMPÃ‰TENCES LES PLUS DEMANDÃ‰ES (TOP offres)\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Collecter toutes les compÃ©tences des 10 meilleures offres\n",
    "    from collections import Counter\n",
    "    \n",
    "    all_requirements = []\n",
    "    for job in recommendations[:10]:\n",
    "        all_requirements.extend(job['requirements'])\n",
    "    \n",
    "    # Compter les occurrences\n",
    "    skill_counts = Counter(all_requirements)\n",
    "    \n",
    "    print(f\"\\nğŸ“‹ TOP 15 compÃ©tences recherchÃ©es :\")\n",
    "    for skill, count in skill_counts.most_common(15):\n",
    "        bar = \"â–ˆ\" * count\n",
    "        print(f\"   â€¢ {skill:40s} : {bar} ({count})\")\n",
    "    \n",
    "    # CompÃ©tences manquantes (dans les requirements mais pas dans le CV)\n",
    "    print(f\"\\nâš ï¸  CompÃ©tences Ã  dÃ©velopper (prÃ©sentes dans les TOP offres) :\")\n",
    "    \n",
    "    cv_skills_lower = [s.lower() for s in cv_skills]\n",
    "    missing_skills = set()\n",
    "    \n",
    "    for job in recommendations[:10]:\n",
    "        for req in job['requirements']:\n",
    "            req_lower = req.lower()\n",
    "            # VÃ©rification simple (pas de matching sÃ©mantique ici)\n",
    "            if not any(cv_skill in req_lower or req_lower in cv_skill \n",
    "                      for cv_skill in cv_skills_lower):\n",
    "                missing_skills.add(req)\n",
    "    \n",
    "    if missing_skills:\n",
    "        for skill in sorted(missing_skills)[:10]:\n",
    "            print(f\"   â€¢ {skill}\")\n",
    "    else:\n",
    "        print(\"   âœ… Vous avez toutes les compÃ©tences principales !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cecd75bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ’¾ RÃ©sultats sauvegardÃ©s : c:\\Users\\rober\\OneDrive\\Bureau\\PFE\\outputs\\job_recommendations.json\n",
      "ğŸ“Š Taille : 45.0 KB\n",
      "\n",
      "âœ… Recommandation d'offres terminÃ©e avec succÃ¨s !\n",
      "\n",
      "ğŸ“‹ RÃ©sumÃ© :\n",
      "   â€¢ 25 offres analysÃ©es\n",
      "   â€¢ TOP offre : Data Scientist Junior (66.7%)\n",
      "   â€¢ Meilleure catÃ©gorie : data_scientist (56.8%)\n",
      "\n",
      "ğŸ“‚ Fichiers gÃ©nÃ©rÃ©s :\n",
      "   â€¢ c:\\Users\\rober\\OneDrive\\Bureau\\PFE\\outputs\\job_recommendations.json\n"
     ]
    }
   ],
   "source": [
    "# Sauvegarder les recommandations\n",
    "if 'recommendations' in locals() and recommendations:\n",
    "    output_dir = project_root / \"outputs\"\n",
    "    output_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    output_path = output_dir / \"job_recommendations.json\"\n",
    "    \n",
    "    # Statistiques dÃ©taillÃ©es\n",
    "    stats = {\n",
    "        \"excellent_match\": len([j for j in recommendations if j['global_score'] >= 70]),\n",
    "        \"good_match\": len([j for j in recommendations if 50 <= j['global_score'] < 70]),\n",
    "        \"medium_match\": len([j for j in recommendations if 40 <= j['global_score'] < 50]),\n",
    "        \"low_match\": len([j for j in recommendations if j['global_score'] < 40]),\n",
    "        \"best_score\": recommendations[0]['global_score'],\n",
    "        \"worst_score\": recommendations[-1]['global_score'],\n",
    "        \"average_score\": sum(r['global_score'] for r in recommendations) / len(recommendations),\n",
    "        \"best_category\": None,\n",
    "        \"category_scores\": {}\n",
    "    }\n",
    "    \n",
    "    # Calculer les scores par catÃ©gorie\n",
    "    categories = set(job.get('category', 'unknown') for job in all_jobs)\n",
    "    for category in categories:\n",
    "        cat_jobs = [r for r in recommendations \n",
    "                    if any(j['job_id'] == r['job_id'] and j.get('category') == category \n",
    "                          for j in all_jobs)]\n",
    "        if cat_jobs:\n",
    "            avg_score = sum(j['global_score'] for j in cat_jobs) / len(cat_jobs)\n",
    "            stats['category_scores'][category] = round(avg_score, 1)\n",
    "    \n",
    "    # Meilleure catÃ©gorie\n",
    "    if stats['category_scores']:\n",
    "        stats['best_category'] = max(stats['category_scores'].items(), key=lambda x: x[1])[0]\n",
    "    \n",
    "    save_data = {\n",
    "        \"cv_file\": cv_data.get('cv_file', 'RESUME ROBERT UNG.pdf'),\n",
    "        \"analysis_date\": \"2026-01-25\",\n",
    "        \"model\": matcher.model_name if matcher else \"all-mpnet-base-v2\",\n",
    "        \"total_jobs_analyzed\": len(all_jobs),\n",
    "        \"cv_skills_count\": len(cv_skills),\n",
    "        \"top_10_recommendations\": recommendations[:10],\n",
    "        \"all_recommendations\": recommendations,\n",
    "        \"statistics\": stats\n",
    "    }\n",
    "    \n",
    "    with open(output_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(save_data, f, indent=2, ensure_ascii=False)\n",
    "    \n",
    "    print(f\"\\nğŸ’¾ RÃ©sultats sauvegardÃ©s : {output_path}\")\n",
    "    print(f\"ğŸ“Š Taille : {output_path.stat().st_size / 1024:.1f} KB\")\n",
    "    \n",
    "    print(\"\\nâœ… Recommandation d'offres terminÃ©e avec succÃ¨s !\")\n",
    "    print(f\"\\nğŸ“‹ RÃ©sumÃ© :\")\n",
    "    print(f\"   â€¢ {len(recommendations)} offres analysÃ©es\")\n",
    "    print(f\"   â€¢ TOP offre : {recommendations[0]['title']} ({recommendations[0]['global_score']:.1f}%)\")\n",
    "    print(f\"   â€¢ Meilleure catÃ©gorie : {stats['best_category']} ({stats['category_scores'].get(stats['best_category'], 0):.1f}%)\")\n",
    "    print(f\"\\nğŸ“‚ Fichiers gÃ©nÃ©rÃ©s :\")\n",
    "    print(f\"   â€¢ {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ba2c5420",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "ğŸ“ˆ RAPPORT VISUEL DES RECOMMANDATIONS\n",
      "======================================================================\n",
      "\n",
      "ğŸ“Š Distribution des scores :\n",
      "   < 40%  ğŸ”´ :  (0)\n",
      "   40-50% ğŸŸ  : â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ (9)\n",
      "   50-60% ğŸŸ¡ : â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ (13)\n",
      "   60-70% ğŸŸ¢ : â–ˆâ–ˆâ–ˆ (3)\n",
      "   â‰¥ 70%  ğŸŸ¢ :  (0)\n",
      "\n",
      "ğŸ¢ Top 5 entreprises par score moyen :\n",
      "   1. Analytics Pro                  : 66.7%\n",
      "   2. WebDev Studio                  : 64.4%\n",
      "   3. AI Startup Paris               : 61.2%\n",
      "   4. MarketingTech                  : 58.3%\n",
      "   5. FinTech Solutions              : 58.3%\n",
      "\n",
      "ğŸ¯ OFFRES PRIORITAIRES (score â‰¥ 60% et < 50 candidats) :\n",
      "   âš ï¸  Aucune offre prioritaire trouvÃ©e (critÃ¨res : score â‰¥60%, candidats <50)\n",
      "\n",
      "======================================================================\n",
      "âœ… Analyse complÃ¨te terminÃ©e !\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# GÃ©nÃ©rer un rapport visuel simple (sans matplotlib)\n",
    "if 'recommendations' in locals() and recommendations:\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"ğŸ“ˆ RAPPORT VISUEL DES RECOMMANDATIONS\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Distribution des scores (histogramme ASCII)\n",
    "    print(f\"\\nğŸ“Š Distribution des scores :\")\n",
    "    \n",
    "    ranges = [\n",
    "        (0, 40, \"< 40%  ğŸ”´\"),\n",
    "        (40, 50, \"40-50% ğŸŸ \"),\n",
    "        (50, 60, \"50-60% ğŸŸ¡\"),\n",
    "        (60, 70, \"60-70% ğŸŸ¢\"),\n",
    "        (70, 100, \"â‰¥ 70%  ğŸŸ¢\")\n",
    "    ]\n",
    "    \n",
    "    for min_score, max_score, label in ranges:\n",
    "        count = len([j for j in recommendations \n",
    "                    if min_score <= j['global_score'] < max_score])\n",
    "        bar = \"â–ˆ\" * count\n",
    "        print(f\"   {label} : {bar} ({count})\")\n",
    "    \n",
    "    # Top 5 entreprises\n",
    "    print(f\"\\nğŸ¢ Top 5 entreprises par score moyen :\")\n",
    "    companies = {}\n",
    "    for job in recommendations:\n",
    "        company = job['company']\n",
    "        if company not in companies:\n",
    "            companies[company] = []\n",
    "        companies[company].append(job['global_score'])\n",
    "    \n",
    "    company_avg = {c: sum(scores)/len(scores) for c, scores in companies.items()}\n",
    "    for i, (company, avg_score) in enumerate(sorted(company_avg.items(), \n",
    "                                                     key=lambda x: x[1], \n",
    "                                                     reverse=True)[:5], 1):\n",
    "        print(f\"   {i}. {company:30s} : {avg_score:.1f}%\")\n",
    "    \n",
    "    # Offres Ã  candidater en prioritÃ©\n",
    "    print(f\"\\nğŸ¯ OFFRES PRIORITAIRES (score â‰¥ 60% et < 50 candidats) :\")\n",
    "    priority_jobs = [j for j in recommendations \n",
    "                     if j['global_score'] >= 60 and j['applicants'] < 50]\n",
    "    \n",
    "    if priority_jobs:\n",
    "        for i, job in enumerate(priority_jobs[:5], 1):\n",
    "            print(f\"   {i}. {job['title']:40s} | Score: {job['global_score']:.1f}% | {job['applicants']} candidats\")\n",
    "    else:\n",
    "        print(\"   âš ï¸  Aucune offre prioritaire trouvÃ©e (critÃ¨res : score â‰¥60%, candidats <50)\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"âœ… Analyse complÃ¨te terminÃ©e !\")\n",
    "    print(\"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
