{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "97fdf246",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Imports termin√©s\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Notebook : Setup et test du Vector Store FAISS\n",
    "Objectif : Cr√©er l'index vectoriel pour acc√©l√©rer le matching\n",
    "\"\"\"\n",
    "\n",
    "# ========================================\n",
    "# CELLULE 1 : Imports et setup\n",
    "# ========================================\n",
    "\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "import json\n",
    "from pathlib import Path\n",
    "from vector_store import JobVectorStore, create_vector_store_from_dataset, load_vector_store\n",
    "import time\n",
    "\n",
    "print(\"‚úÖ Imports termin√©s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b3c76a28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Jobs dataset charg√© (structure par cat√©gorie)\n",
      "üìÇ Cat√©gories : ['metadata', 'jobs']\n",
      "‚úÖ 25 offres charg√©es au total\n",
      "\n",
      "üìã Exemple d'offre :\n",
      "{\n",
      "  \"job_id\": \"job_001\",\n",
      "  \"category\": \"ml_engineer\",\n",
      "  \"title\": \"Junior ML Engineer\",\n",
      "  \"company\": \"AI Startup Paris\",\n",
      "  \"location\": \"Toulouse, France\",\n",
      "  \"type\": \"CDI\",\n",
      "  \"experience\": \"0-2 ans\",\n",
      "  \"salary\": \"35-45K‚Ç¨\",\n",
      "  \"description\": \"Nous recherchons un Junior ML Engineer passionn√© pour rejoindre notre √©quipe R&D.\\n\\nResponsabilit√©s :\\n- D√©velopper des mod√®les de Machine Learning (classification, r√©gression)\\n- Entra√Æner et optimiser des r√©seaux de neurones avec PyTorch\\n- D√©ployer des mod√®les en production avec Docker\\n- Participer aux revues de code et √† l'am√©lioration continue\\n\\nStack technique :\\n- Python, PyTorch, scikit-learn\\n- Docker, Git\\n- FastAPI pour les APIs\\n- PostgreSQL\",\n",
      "  \"requirements\": [\n",
      "    \"Python (numpy, pandas, scikit-learn)\",\n",
      "    \"Machine Learning basics (supervised learning)\",\n",
      "    \"Git et GitHub\",\n",
      "    \"Docker (notions de base)\",\n",
      "    \"Anglais technique (lecture documentation)\"\n",
      "  ],\n",
      "  \"nice_to_have\": [\n",
      "    \"PyTorch ou TensorFlow\",\n",
      "    \"FastAPI ou Flask\",\n",
      "    \"MLflow\",\n",
      "    \"AWS ou GCP\"\n",
      "  ],\n",
      "  \"posted_date\": \"2026-01-08\",\n",
      "  \"url\": \"https://example-jobs.com/1\",\n",
      "  \"remote_ok\": false,\n",
      "  \"applicants\": 99\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# ========================================\n",
    "# CELLULE 2 : Charger les offres d'emploi\n",
    "# ========================================\n",
    "\n",
    "jobs_path = Path(\"../data/jobs/jobs_dataset.json\")\n",
    "\n",
    "if not jobs_path.exists():\n",
    "    print(\"‚ùå Fichier jobs_dataset.json introuvable\")\n",
    "    print(\"üí° Ex√©cutez d'abord 04_job_generation.ipynb\")\n",
    "else:\n",
    "    with open(jobs_path, 'r', encoding='utf-8') as f:\n",
    "        jobs_data = json.load(f)\n",
    "    \n",
    "    # V√©rifier la structure du fichier\n",
    "    if isinstance(jobs_data, dict):\n",
    "        # Si c'est un dictionnaire (organis√© par cat√©gorie)\n",
    "        print(f\"‚úÖ Jobs dataset charg√© (structure par cat√©gorie)\")\n",
    "        print(f\"üìÇ Cat√©gories : {list(jobs_data.keys())}\")\n",
    "        \n",
    "        # Aplatir en une seule liste\n",
    "        jobs = []\n",
    "        for category, job_list in jobs_data.items():\n",
    "            if isinstance(job_list, list):\n",
    "                jobs.extend(job_list)\n",
    "        \n",
    "        print(f\"‚úÖ {len(jobs)} offres charg√©es au total\\n\")\n",
    "        \n",
    "    elif isinstance(jobs_data, list):\n",
    "        # Si c'est d√©j√† une liste\n",
    "        jobs = jobs_data\n",
    "        print(f\"‚úÖ {len(jobs)} offres charg√©es\\n\")\n",
    "    else:\n",
    "        print(\"‚ùå Format de fichier JSON non reconnu\")\n",
    "        jobs = []\n",
    "    \n",
    "    # Afficher un exemple\n",
    "    if jobs:\n",
    "        print(f\"üìã Exemple d'offre :\")\n",
    "        print(json.dumps(jobs[0], indent=2, ensure_ascii=False))\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è Aucune offre trouv√©e dans le fichier\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bc2ee1e",
   "metadata": {},
   "source": [
    "le code Lit le fichier jobs_dataset.json. Si les offres sont organis√©es par cat√©gorie (dict), elle les fusionne en une liste unique. \n",
    "\n",
    "Les offres charg√©es ici seront index√©es par FAISS dans la Cellule 3  /// FAISS est la  biblioth√®que d√©velopp√©e par Facebook (Meta)  pour la recherche de similarit√© ultra-rapide dans des vecteurs de grande dimension "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "be47e9dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üî® Cr√©ation du Vector Store FAISS...\n",
      "‚è±Ô∏è Temps estim√© : 30-60 secondes\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee861d9731f048f3ac1b36f75baf5968",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/199 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MPNetModel LOAD REPORT from: sentence-transformers/all-mpnet-base-v2\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "Notes:\n",
      "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üî® Construction de l'index FAISS pour 25 offres...\n",
      "üìä G√©n√©ration des embeddings...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02fea30445d84f688aa132c7cbef432a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Cr√©ation de l'index FAISS...\n",
      "‚úÖ Index construit : 25 offres index√©es\n",
      "\n",
      "‚úÖ Index cr√©√© en 14.7 secondes\n",
      "üìä Statistiques : {'status': 'trained', 'total_jobs': 25, 'dimension': 768, 'model': 'all-mpnet-base-v2'}\n"
     ]
    }
   ],
   "source": [
    "# ========================================\n",
    "# CELLULE 3 : Cr√©er et entra√Æner le Vector Store (option A avec all-mpnet-base-v2\tDimensions : 768)\n",
    "# ========================================\n",
    "\n",
    "print(\"üî® Cr√©ation du Vector Store FAISS...\")\n",
    "print(\"‚è±Ô∏è Temps estim√© : 30-60 secondes\\n\")\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "# Cr√©er vector store\n",
    "vector_store = JobVectorStore(model_name=\"all-mpnet-base-v2\")\n",
    "\n",
    "# Construire index\n",
    "vector_store.build_index(jobs)\n",
    "\n",
    "elapsed = time.time() - start_time\n",
    "\n",
    "print(f\"\\n‚úÖ Index cr√©√© en {elapsed:.1f} secondes\")\n",
    "print(f\"üìä Statistiques : {vector_store.get_stats()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07de84f3",
   "metadata": {},
   "source": [
    "- Charge le mod√®le Sentence-Transformers (all-mpnet-base-v2) pour cr√©er des embeddings\n",
    "- Pour chaque offre :\n",
    "** Combine titre + description ‚Üí \"Data Scientist. Python, ML, TensorFlow...\"\n",
    "** Transforme ce texte en vecteur de 768 dimensions (embedding)\n",
    "\n",
    "- Cr√©e un index FAISS qui stocke ces 25 vecteurs de mani√®re optimis√©e\n",
    "- Normalise les vecteurs pour calculer la similarit√© cosinus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ea6b6de9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ CV de test charg√©\n",
      "\n",
      "üîç Recherche des 10 offres les plus pertinentes...\n",
      "‚ö° Recherche termin√©e en 3.192 secondes\n",
      "\n",
      "üéØ TOP 10 R√âSULTATS :\n",
      "\n",
      "1. Junior ML Engineer - AI Startup Paris\n",
      "   Score FAISS : 41.0%\n",
      "   Localisation : Toulouse, France\n",
      "\n",
      "2. Data Scientist - Finance - FinTech Solutions\n",
      "   Score FAISS : 38.2%\n",
      "   Localisation : Toulouse, France\n",
      "\n",
      "3. Senior ML Engineer - BigTech France\n",
      "   Score FAISS : 37.9%\n",
      "   Localisation : Remote France\n",
      "\n",
      "4. SRE Engineer - ScaleOps\n",
      "   Score FAISS : 37.6%\n",
      "   Localisation : Paris, France\n",
      "\n",
      "5. MLOps Engineer - DataCorp\n",
      "   Score FAISS : 35.8%\n",
      "   Localisation : Lyon, France\n",
      "\n",
      "6. ML Engineer - Computer Vision - VisionTech\n",
      "   Score FAISS : 35.6%\n",
      "   Localisation : Paris (Hybrid)\n",
      "\n",
      "7. Senior Python Developer - Enterprise Tech\n",
      "   Score FAISS : 35.3%\n",
      "   Localisation : Paris (Hybrid)\n",
      "\n",
      "8. Python Developer - Data Engineering - BigData Corp\n",
      "   Score FAISS : 33.3%\n",
      "   Localisation : Bordeaux, France\n",
      "\n",
      "9. Full Stack JavaScript Developer - Digital Agency\n",
      "   Score FAISS : 33.2%\n",
      "   Localisation : Bordeaux, France\n",
      "\n",
      "10. Lead Data Scientist - DataLab\n",
      "   Score FAISS : 31.3%\n",
      "   Localisation : Nantes, France\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ========================================\n",
    "# CELLULE 4 : Test de recherche (CV exemple)\n",
    "# ========================================\n",
    "\n",
    "# Charger un CV de test\n",
    "cv_text_path = Path(\"cv_text_pdfplumber.txt\")\n",
    "\n",
    "if cv_text_path.exists():\n",
    "    with open(cv_text_path, 'r', encoding='utf-8') as f:\n",
    "        cv_text = f.read()\n",
    "    \n",
    "    print(\"‚úÖ CV de test charg√©\\n\")\n",
    "    \n",
    "    # Recherche rapide\n",
    "    print(\"üîç Recherche des 10 offres les plus pertinentes...\")\n",
    "    \n",
    "    start_search = time.time()\n",
    "    results = vector_store.search(cv_text, top_k=10, min_score=0.3)\n",
    "    search_time = time.time() - start_search\n",
    "    \n",
    "    print(f\"‚ö° Recherche termin√©e en {search_time:.3f} secondes\\n\")\n",
    "    \n",
    "    # Afficher r√©sultats\n",
    "    print(f\"üéØ TOP {len(results)} R√âSULTATS :\\n\")\n",
    "    for i, job in enumerate(results, 1):\n",
    "        print(f\"{i}. {job['title']} - {job['company']}\")\n",
    "        print(f\"   Score FAISS : {job['faiss_score_percent']:.1f}%\")\n",
    "        print(f\"   Localisation : {job['location']}\")\n",
    "        print()\n",
    "\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Pas de CV de test trouv√©\")\n",
    "    print(\"üí° Utilisez 01_cv_parser.ipynb pour g√©n√©rer cv_text_pdfplumber.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c4c952f",
   "metadata": {},
   "source": [
    "- Transforme ton CV en vecteur (embedding)\n",
    "- Compare ce vecteur avec les 25 offres stock√©es dans FAISS\n",
    "- Retourne les 10 offres les plus similaires avec un score de 0 √† 100%\n",
    "\n",
    "Pourquoi c'est rapide ?\n",
    "\n",
    "* Sans FAISS : Il faudrait calculer 25 embeddings √† chaque recherche (~30s)\n",
    "* Avec FAISS : Les embeddings sont d√©j√† calcul√©s, on fait juste une comparaison (~0.5s)\n",
    "\n",
    "cette cellule Utilise l'index de la Cellule 3 pour chercher. Les r√©sultats seront compar√©s dans la Cellule 7."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "59ed46d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Index sauvegard√© : ../models/faiss_jobs.index\n",
      "‚úÖ M√©tadonn√©es sauvegard√©es : ../models/faiss_jobs_metadata.pkl\n",
      "üìå Mod√®le utilis√© : all-mpnet-base-v2 (768 dimensions)\n",
      "\n",
      "‚úÖ Vector Store sauvegard√© !\n",
      "üìÅ Index : ../models/faiss_jobs.index\n",
      "üìÅ M√©tadonn√©es : ../models/faiss_jobs_metadata.pkl\n",
      "üíæ Taille index : 75.0 KB\n"
     ]
    }
   ],
   "source": [
    "# ========================================\n",
    "# CELLULE 5 : Sauvegarder l'index\n",
    "# ========================================\n",
    "\n",
    "# Cr√©er dossier models/\n",
    "models_dir = Path(\"../models\")\n",
    "models_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Sauvegarder\n",
    "index_path = models_dir / \"faiss_jobs.index\"\n",
    "metadata_path = models_dir / \"faiss_jobs_metadata.pkl\"\n",
    "\n",
    "vector_store.save(str(index_path), str(metadata_path))\n",
    "\n",
    "print(f\"\\n‚úÖ Vector Store sauvegard√© !\")\n",
    "print(f\"üìÅ Index : {index_path}\")\n",
    "print(f\"üìÅ M√©tadonn√©es : {metadata_path}\")\n",
    "print(f\"üíæ Taille index : {index_path.stat().st_size / 1024:.1f} KB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5961abb",
   "metadata": {},
   "source": [
    "Ce qu'elle fait :\n",
    "\n",
    "* Sauvegarde l'index FAISS sur le disque (fichier .index)\n",
    "* Sauvegarde les m√©tadonn√©es (titres, entreprises, etc.) dans un fichier .pkl\n",
    "\n",
    "Pourquoi c'est important ?\n",
    "\n",
    "* Sans sauvegarde : Tu dois recalculer les embeddings √† chaque fois (30-60s)\n",
    "* Avec sauvegarde : Tu charges l'index en 2 secondes et c'est pr√™t !\n",
    "\n",
    "\n",
    "Ces fichiers seront recharg√©s dans la Cellule 6 et utilis√©s par l'API plus tard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "84676720",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Test de rechargement de l'index...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbbbd4af6c704ad9b65340f503624bf8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/199 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MPNetModel LOAD REPORT from: sentence-transformers/all-mpnet-base-v2\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "Notes:\n",
      "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Index charg√© : 25 offres\n",
      "üìå Mod√®le final : all-mpnet-base-v2 (768 dimensions)\n",
      "‚úÖ Index recharg√© : {'status': 'trained', 'total_jobs': 25, 'dimension': 768, 'model': 'all-mpnet-base-v2'}\n",
      "\n",
      "‚ö° Recherche avec index charg√© : 2.046s\n",
      "üéØ 5 r√©sultats retourn√©s\n"
     ]
    }
   ],
   "source": [
    "# ========================================\n",
    "# CELLULE 6 : Test de chargement (AUTO-D√âTECTION)\n",
    "# ========================================\n",
    "\n",
    "print(\"üîÑ Test de rechargement de l'index...\\n\")\n",
    "\n",
    "# üÜï Plus besoin de sp√©cifier le mod√®le !\n",
    "# Il sera automatiquement d√©tect√© depuis les m√©tadonn√©es\n",
    "vs_loaded = JobVectorStore()\n",
    "\n",
    "# Charger index sauvegard√©\n",
    "vs_loaded.load(str(index_path), str(metadata_path))\n",
    "\n",
    "print(f\"‚úÖ Index recharg√© : {vs_loaded.get_stats()}\")\n",
    "\n",
    "# Test recherche rapide\n",
    "if cv_text_path.exists():\n",
    "    start = time.time()\n",
    "    results_loaded = vs_loaded.search(cv_text, top_k=5)\n",
    "    elapsed = time.time() - start\n",
    "    \n",
    "    print(f\"\\n‚ö° Recherche avec index charg√© : {elapsed:.3f}s\")\n",
    "    print(f\"üéØ {len(results_loaded)} r√©sultats retourn√©s\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Pas de CV pour tester\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e5a7037",
   "metadata": {},
   "source": [
    "Ce qu'elle fait :\n",
    "\n",
    "    Cr√©e un nouveau vector store (vide)\n",
    "    Charge l'index sauvegard√© dans la Cellule 5\n",
    "    Teste une recherche pour v√©rifier que tout fonctionne\n",
    "\n",
    "Pourquoi ce test ?\n",
    "\n",
    "    V√©rifie que la sauvegarde a bien march√©\n",
    "    Simule ce qui se passera dans l'API (charger un index existant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d4831c3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "üìä COMPARAISON DE PERFORMANCES\n",
      "============================================================\n",
      "\n",
      "üê¢ M√©thode classique (sans FAISS)\n",
      "   Temps estim√© : ~30-60 secondes\n",
      "   Raison : Calcul embeddings + comparaison pour chaque offre\n",
      "\n",
      "‚ö° M√©thode FAISS (avec index)\n",
      "   Temps r√©el : 3.455 secondes\n",
      "   Gain : ~17x plus rapide !\n",
      "\n",
      "‚úÖ FAISS est LA solution pour scaler √† 100+ offres\n"
     ]
    }
   ],
   "source": [
    "# ========================================\n",
    "# CELLULE 7 : Comparaison de performances\n",
    "# ========================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üìä COMPARAISON DE PERFORMANCES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "if cv_text_path.exists():\n",
    "    # M√©thode 1 : Sans FAISS (matching classique - simulation)\n",
    "    print(\"\\nüê¢ M√©thode classique (sans FAISS)\")\n",
    "    print(\"   Temps estim√© : ~30-60 secondes\")\n",
    "    print(\"   Raison : Calcul embeddings + comparaison pour chaque offre\")\n",
    "    \n",
    "    # M√©thode 2 : Avec FAISS\n",
    "    print(\"\\n‚ö° M√©thode FAISS (avec index)\")\n",
    "    start = time.time()\n",
    "    faiss_results = vector_store.search(cv_text, top_k=25)\n",
    "    faiss_time = time.time() - start\n",
    "    \n",
    "    print(f\"   Temps r√©el : {faiss_time:.3f} secondes\")\n",
    "    print(f\"   Gain : ~{60/faiss_time:.0f}x plus rapide !\")\n",
    "    \n",
    "    print(\"\\n‚úÖ FAISS est LA solution pour scaler √† 100+ offres\")\n",
    "\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è Pas de CV pour tester les performances\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b98b2bfb",
   "metadata": {},
   "source": [
    "Ce qu'elle fait :\n",
    "\n",
    "    Mesure le temps de recherche avec FAISS\n",
    "    Compare avec le temps sans FAISS (estim√© √† 30-60s)\n",
    "    Calcule le gain de performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c625f34a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      " VALIDATION - VECTOR STORE FAISS\n",
      "============================================================\n",
      "‚úÖ Index FAISS cr√©√©\n",
      "‚úÖ Index sauvegard√© sur disque\n",
      "‚úÖ M√©tadonn√©es sauvegard√©es\n",
      "‚úÖ Rechargement fonctionne\n",
      "‚ùå Recherche rapide (<1s)\n",
      "‚úÖ R√©sultats pertinents\n",
      "\n",
      "üìä SCORE : 5/6 (83%)\n",
      "\n",
      "‚ö†Ô∏è Quelques ajustements n√©cessaires\n",
      "\n",
      "üí° Utilisation dans l'API :\n",
      "```python\n",
      "from vector_store import load_vector_store\n",
      "vs = load_vector_store()\n",
      "results = vs.search(cv_text, top_k=10)\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "# ========================================\n",
    "# CELLULE 8 : VALIDATION FINALE\n",
    "# ========================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\" VALIDATION - VECTOR STORE FAISS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "checks = {\n",
    "    \"‚úÖ Index FAISS cr√©√©\": vector_store.is_trained,\n",
    "    \"‚úÖ Index sauvegard√© sur disque\": index_path.exists(),\n",
    "    \"‚úÖ M√©tadonn√©es sauvegard√©es\": metadata_path.exists(),\n",
    "    \"‚úÖ Rechargement fonctionne\": vs_loaded.is_trained,\n",
    "    \"‚úÖ Recherche rapide (<1s)\": 'faiss_time' in locals() and faiss_time < 1.0,\n",
    "    \"‚úÖ R√©sultats pertinents\": len(results) > 0 if 'results' in locals() else False\n",
    "}\n",
    "\n",
    "for check, passed in checks.items():\n",
    "    status = check if passed else check.replace(\"‚úÖ\", \"‚ùå\")\n",
    "    print(status)\n",
    "\n",
    "score = sum(checks.values())\n",
    "total = len(checks)\n",
    "\n",
    "print(f\"\\nüìä SCORE : {score}/{total} ({score/total*100:.0f}%)\")\n",
    "\n",
    "if score == total:\n",
    "    print(\"\\nüéâ VECTOR STORE OP√âRATIONNEL !\")\n",
    "    print(\"üëâ Prochaine √©tape : Int√©grer FAISS dans l'API\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è Quelques ajustements n√©cessaires\")\n",
    "\n",
    "print(\"\\nüí° Utilisation dans l'API :\")\n",
    "print(\"```python\")\n",
    "print(\"from vector_store import load_vector_store\")\n",
    "print(\"vs = load_vector_store()\")\n",
    "print(\"results = vs.search(cv_text, top_k=10)\")\n",
    "print(\"```\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a5bf7dee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß™ TEST DE COMPATIBILIT√â MULTI-MOD√àLES\n",
      "============================================================\n",
      "\n",
      "üìå Test 1 : Chargement avec mod√®le identique\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73eeeb44eba24d918679900e5bce1114",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/199 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MPNetModel LOAD REPORT from: sentence-transformers/all-mpnet-base-v2\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "Notes:\n",
      "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Index charg√© : 25 offres\n",
      "üìå Mod√®le final : all-mpnet-base-v2 (768 dimensions)\n",
      "‚úÖ Test 1 r√©ussi\n",
      "\n",
      "üìå Test 2 : Chargement avec mod√®le diff√©rent (auto-correction)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9f6b25020cf4da1b7462ebe1f24101b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/103 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "BertModel LOAD REPORT from: sentence-transformers/all-MiniLM-L6-v2\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "Notes:\n",
      "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö†Ô∏è Mod√®le diff√©rent d√©tect√© !\n",
      "   - Index sauvegard√© avec : all-mpnet-base-v2 (768 dim)\n",
      "   - Mod√®le actuel : all-MiniLM-L6-v2 (384 dim)\n",
      "üîÑ Chargement du mod√®le correct...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3f89d15737d4a00b954f029db4fc022",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/199 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MPNetModel LOAD REPORT from: sentence-transformers/all-mpnet-base-v2\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "Notes:\n",
      "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Mod√®le recharg√© : all-mpnet-base-v2\n",
      "‚úÖ Index charg√© : 25 offres\n",
      "üìå Mod√®le final : all-mpnet-base-v2 (768 dimensions)\n",
      "‚úÖ Test 2 r√©ussi : mod√®le auto-corrig√© en all-mpnet-base-v2\n",
      "\n",
      "üìå Test 3 : Chargement via fonction utilitaire\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36e903f5f1c2486d95e3b71496a3fa1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading weights:   0%|          | 0/199 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "MPNetModel LOAD REPORT from: sentence-transformers/all-mpnet-base-v2\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "Notes:\n",
      "- UNEXPECTED\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Index charg√© : 25 offres\n",
      "üìå Mod√®le final : all-mpnet-base-v2 (768 dimensions)\n",
      "‚úÖ Test 3 r√©ussi : all-mpnet-base-v2 charg√© automatiquement\n",
      "\n",
      "üéâ Tous les tests de compatibilit√© pass√©s !\n"
     ]
    }
   ],
   "source": [
    "# ========================================\n",
    "# CELLULE 9 : Test de compatibilit√© multi-mod√®les\n",
    "# ========================================\n",
    "\n",
    "print(\"üß™ TEST DE COMPATIBILIT√â MULTI-MOD√àLES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Test 1 : Charger avec le m√™me mod√®le (normal)\n",
    "print(\"\\nüìå Test 1 : Chargement avec mod√®le identique\")\n",
    "vs_test1 = JobVectorStore(model_name=\"all-mpnet-base-v2\")\n",
    "vs_test1.load(str(index_path), str(metadata_path))\n",
    "print(f\"‚úÖ Test 1 r√©ussi\\n\")\n",
    "\n",
    "# Test 2 : Charger avec un mod√®le diff√©rent (auto-correction)\n",
    "print(\"üìå Test 2 : Chargement avec mod√®le diff√©rent (auto-correction)\")\n",
    "vs_test2 = JobVectorStore(model_name=\"all-MiniLM-L6-v2\")  # Mod√®le diff√©rent\n",
    "vs_test2.load(str(index_path), str(metadata_path))  # Doit auto-corriger\n",
    "print(f\"‚úÖ Test 2 r√©ussi : mod√®le auto-corrig√© en {vs_test2.model_name}\\n\")\n",
    "\n",
    "# Test 3 : Fonction load_vector_store (sans sp√©cifier le mod√®le)\n",
    "print(\"üìå Test 3 : Chargement via fonction utilitaire\")\n",
    "vs_test3 = load_vector_store(str(index_path), str(metadata_path))\n",
    "print(f\"‚úÖ Test 3 r√©ussi : {vs_test3.model_name} charg√© automatiquement\\n\")\n",
    "\n",
    "print(\"üéâ Tous les tests de compatibilit√© pass√©s !\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e690441",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pfe",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
