{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09c2d757",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "üìÇ CHARGEMENT DES OFFRES\n",
      "============================================================\n",
      "\n",
      "‚úÖ 25 offres charg√©es\n",
      "üìä Cat√©gories : {'frontend_developer', 'python_developer', 'ml_engineer', 'devops_engineer', 'data_scientist'}\n",
      "\n",
      "üìÑ Exemple d'offre :\n",
      "   ID : job_001\n",
      "   Titre : Junior ML Engineer\n",
      "   Entreprise : AI Startup Paris\n",
      "   Description : Nous recherchons un Junior ML Engineer passionn√© pour rejoindre notre √©quipe R&D.\n",
      "\n",
      "Responsabilit√©s :...\n",
      "   Requirements : ['Python (numpy, pandas, scikit-learn)', 'Machine Learning basics (supervised learning)', 'Git et GitHub']...\n"
     ]
    }
   ],
   "source": [
    "# %% [markdown]\n",
    "# # üóÇÔ∏è Indexation FAISS des Offres d'Emploi\n",
    "# \n",
    "# **Objectif** : Cr√©er un index FAISS pour recherche rapide et scalable\n",
    "# \n",
    "# **Pipeline** :\n",
    "# 1. Charger les offres depuis `jobs_dataset.json`\n",
    "# 2. Cr√©er l'index FAISS avec embeddings\n",
    "# 3. Tester la recherche\n",
    "# 4. Sauvegarder l'index\n",
    "\n",
    "# %%\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import json\n",
    "from pathlib import Path\n",
    "from src.vector_store import JobVectorStore\n",
    "\n",
    "# %%\n",
    "# 1. CHARGEMENT DES OFFRES\n",
    "print(\"=\"*60)\n",
    "print(\"üìÇ CHARGEMENT DES OFFRES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "jobs_path = Path('../data/jobs/jobs_dataset.json')\n",
    "\n",
    "if not jobs_path.exists():\n",
    "    raise FileNotFoundError(\n",
    "        f\"Dataset d'offres introuvable : {jobs_path}\\n\"\n",
    "        \"Ex√©cutez d'abord le notebook 04_job_generation.ipynb\"\n",
    "    )\n",
    "\n",
    "with open(jobs_path, 'r', encoding='utf-8') as f:\n",
    "    dataset = json.load(f)\n",
    "    jobs = dataset['jobs']\n",
    "\n",
    "print(f\"\\n‚úÖ {len(jobs)} offres charg√©es\")\n",
    "print(f\"üìä Cat√©gories : {set(job['category'] for job in jobs)}\")\n",
    "\n",
    "# Afficher un exemple\n",
    "print(f\"\\nüìÑ Exemple d'offre :\")\n",
    "example = jobs[0]\n",
    "print(f\"   ID : {example['job_id']}\")\n",
    "print(f\"   Titre : {example['title']}\")\n",
    "print(f\"   Entreprise : {example['company']}\")\n",
    "print(f\"   Description : {example['description'][:100]}...\")\n",
    "print(f\"   Requirements : {example['requirements'][:3]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2e68ed6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "üî® CONSTRUCTION DE L'INDEX FAISS\n",
      "============================================================\n",
      "‚úÖ JobVectorStore initialis√© avec all-mpnet-base-v2 (768 dimensions)\n",
      "\n",
      "üî® Construction de l'index FAISS...\n",
      "   Nombre d'offres : 25\n",
      "   Type d'index : flat\n",
      "   G√©n√©ration des embeddings...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbf4aba9466845ef85a1f9136c3dfc58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Index construit avec succ√®s !\n",
      "   Total d'offres index√©es : 25\n",
      "\n",
      "üìä Statistiques de l'index :\n",
      "   Offres index√©es : 25\n",
      "   Mod√®le : all-mpnet-base-v2\n",
      "   Dimensions : 768\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# 2. CR√âATION DE L'INDEX FAISS\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üî® CONSTRUCTION DE L'INDEX FAISS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Initialiser le vector store\n",
    "vector_store = JobVectorStore(model_name='all-mpnet-base-v2')\n",
    "\n",
    "# Construire l'index\n",
    "vector_store.build_index(jobs, index_type='flat')\n",
    "\n",
    "# Statistiques\n",
    "stats = vector_store.get_stats()\n",
    "print(f\"\\nüìä Statistiques de l'index :\")\n",
    "print(f\"   Offres index√©es : {stats['total_jobs']}\")\n",
    "print(f\"   Mod√®le : {stats['model_name']}\")\n",
    "print(f\"   Dimensions : {stats['dimension']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c9343ac3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "üîç TEST DE RECHERCHE\n",
      "============================================================\n",
      "\n",
      "üß™ Test 1 : Profil ML Engineer Junior\n",
      "\n",
      "#1 - Score FAISS : 54.41%\n",
      "   üìã Junior ML Engineer\n",
      "   üè¢ AI Startup Paris\n",
      "   üìç Toulouse, France\n",
      "   üíº Exp√©rience : 0-2 ans\n",
      "   üîß Requirements : Python (numpy, pandas, scikit-learn), Machine Learning basics (supervised learning), Git et GitHub, Docker (notions de base), Anglais technique (lecture documentation)\n",
      "\n",
      "#2 - Score FAISS : 53.37%\n",
      "   üìã MLOps Engineer\n",
      "   üè¢ DataCorp\n",
      "   üìç Lyon, France\n",
      "   üíº Exp√©rience : 2-4 ans\n",
      "   üîß Requirements : MLOps (CI/CD pour ML), Docker, Kubernetes, Python, Cloud (AWS ou GCP), Git, GitLab/GitHub Actions\n",
      "\n",
      "#3 - Score FAISS : 49.72%\n",
      "   üìã ML Engineer - Computer Vision\n",
      "   üè¢ VisionTech\n",
      "   üìç Paris (Hybrid)\n",
      "   üíº Exp√©rience : 1-3 ans\n",
      "   üîß Requirements : Deep Learning (CNNs, architectures modernes), PyTorch ou TensorFlow, Computer Vision (OpenCV, PIL), Python avanc√©, Git, Docker\n",
      "\n",
      "#4 - Score FAISS : 47.64%\n",
      "   üìã Senior ML Engineer\n",
      "   üè¢ BigTech France\n",
      "   üìç Remote France\n",
      "   üíº Exp√©rience : 3-5 ans\n",
      "   üîß Requirements : 5+ ans en Machine Learning, Deep Learning avanc√©, MLOps et architecture, Kubernetes en production, Leadership technique\n",
      "\n",
      "#5 - Score FAISS : 44.46%\n",
      "   üìã Python Developer - Data Engineering\n",
      "   üè¢ BigData Corp\n",
      "   üìç Bordeaux, France\n",
      "   üíº Exp√©rience : 2-4 ans\n",
      "   üîß Requirements : Python (pandas, numpy), ETL et data pipelines, SQL avanc√©, Airflow, Cloud (AWS ou GCP)\n",
      "\n",
      "------------------------------------------------------------\n",
      "üß™ Test 2 : Profil Data Scientist\n",
      "\n",
      "#1 - Score FAISS : 37.96%\n",
      "   üìã Data Scientist Junior\n",
      "   üè¢ Analytics Pro\n",
      "   üîß Requirements : Python (pandas, numpy, matplotlib), Machine Learning (scikit-learn), SQL, Statistiques, Communication (pr√©sentation de r√©sultats)\n",
      "\n",
      "#2 - Score FAISS : 27.43%\n",
      "   üìã Python Developer - Data Engineering\n",
      "   üè¢ BigData Corp\n",
      "   üîß Requirements : Python (pandas, numpy), ETL et data pipelines, SQL avanc√©, Airflow, Cloud (AWS ou GCP)\n",
      "\n",
      "#3 - Score FAISS : 24.40%\n",
      "   üìã Data Scientist - Marketing\n",
      "   üè¢ MarketingTech\n",
      "   üîß Requirements : Python et/ou R, Machine Learning (classification, clustering), SQL avanc√©, Statistiques et A/B testing, Visualisation de donn√©es\n",
      "\n",
      "#4 - Score FAISS : 21.84%\n",
      "   üìã Python Developer Junior\n",
      "   üè¢ WebDev Studio\n",
      "   üîß Requirements : Python (bonnes pratiques), APIs RESTful, SQL, Git, Tests unitaires (pytest)\n",
      "\n",
      "#5 - Score FAISS : 18.61%\n",
      "   üìã Data Scientist - Finance\n",
      "   üè¢ FinTech Solutions\n",
      "   üîß Requirements : Machine Learning (classification, regression), Time series analysis, Python (pandas, scikit-learn), SQL, Statistiques avanc√©es\n",
      "\n",
      "------------------------------------------------------------\n",
      "üß™ Test 3 : Profil DevOps\n",
      "\n",
      "#1 - Score FAISS : 60.16%\n",
      "   üìã DevOps Engineer - Kubernetes\n",
      "   üè¢ ContainerTech\n",
      "   üîß Requirements : Kubernetes (d√©ploiements, services, ingress), Docker avanc√©, Terraform ou Ansible, Cloud (AWS, GCP ou Azure), Monitoring (Prometheus)\n",
      "\n",
      "#2 - Score FAISS : 53.54%\n",
      "   üìã DevOps Engineer Junior\n",
      "   üè¢ CloudOps\n",
      "   üîß Requirements : Docker et containerisation, CI/CD (GitLab ou GitHub Actions), Linux (bash scripting), Git, Cloud basics (AWS ou Azure)\n",
      "\n",
      "#3 - Score FAISS : 45.42%\n",
      "   üìã Lead DevOps Engineer\n",
      "   üè¢ BigCorp\n",
      "   üîß Requirements : 7+ ans en DevOps/SRE, Leadership d'√©quipe, Architecture cloud, Security et compliance, Budget management\n",
      "\n",
      "#4 - Score FAISS : 43.19%\n",
      "   üìã MLOps Engineer\n",
      "   üè¢ DataCorp\n",
      "   üîß Requirements : MLOps (CI/CD pour ML), Docker, Kubernetes, Python, Cloud (AWS ou GCP), Git, GitLab/GitHub Actions\n",
      "\n",
      "#5 - Score FAISS : 40.18%\n",
      "   üìã Platform Engineer\n",
      "   üè¢ InfraTech\n",
      "   üîß Requirements : Kubernetes avanc√©, Infrastructure as Code (Terraform), CI/CD, Developer experience, Scripting (Python, Bash, Go)\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# 3. TEST DE RECHERCHE\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üîç TEST DE RECHERCHE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Test 1 : Profil ML Engineer Junior\n",
    "print(\"\\nüß™ Test 1 : Profil ML Engineer Junior\")\n",
    "cv_skills_ml = [\"Python\", \"Machine Learning\", \"TensorFlow\", \"Docker\", \"FastAPI\", \"scikit-learn\"]\n",
    "results_ml = vector_store.search(cv_skills_ml, top_k=5)\n",
    "\n",
    "for i, (job, score) in enumerate(results_ml, 1):\n",
    "    print(f\"\\n#{i} - Score FAISS : {score:.2f}%\")\n",
    "    print(f\"   üìã {job['title']}\")\n",
    "    print(f\"   üè¢ {job['company']}\")\n",
    "    print(f\"   üìç {job['location']}\")\n",
    "    print(f\"   üíº Exp√©rience : {job['experience']}\")\n",
    "    print(f\"   üîß Requirements : {', '.join(job['requirements'][:5])}\")\n",
    "\n",
    "# Test 2 : Profil Data Scientist\n",
    "print(\"\\n\" + \"-\"*60)\n",
    "print(\"üß™ Test 2 : Profil Data Scientist\")\n",
    "cv_skills_ds = [\"Python\", \"R\", \"SQL\", \"Pandas\", \"Matplotlib\", \"Statistics\", \"A/B Testing\"]\n",
    "results_ds = vector_store.search(cv_skills_ds, top_k=5)\n",
    "\n",
    "for i, (job, score) in enumerate(results_ds, 1):\n",
    "    print(f\"\\n#{i} - Score FAISS : {score:.2f}%\")\n",
    "    print(f\"   üìã {job['title']}\")\n",
    "    print(f\"   üè¢ {job['company']}\")\n",
    "    print(f\"   üîß Requirements : {', '.join(job['requirements'][:5])}\")\n",
    "\n",
    "# Test 3 : Profil DevOps\n",
    "print(\"\\n\" + \"-\"*60)\n",
    "print(\"üß™ Test 3 : Profil DevOps\")\n",
    "cv_skills_devops = [\"Docker\", \"Kubernetes\", \"AWS\", \"Terraform\", \"Jenkins\", \"CI/CD\"]\n",
    "results_devops = vector_store.search(cv_skills_devops, top_k=5)\n",
    "\n",
    "for i, (job, score) in enumerate(results_devops, 1):\n",
    "    print(f\"\\n#{i} - Score FAISS : {score:.2f}%\")\n",
    "    print(f\"   üìã {job['title']}\")\n",
    "    print(f\"   üè¢ {job['company']}\")\n",
    "    print(f\"   üîß Requirements : {', '.join(job['requirements'][:5])}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91b5ec2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "üìä ANALYSE DE LA DISTRIBUTION\n",
      "============================================================\n",
      "\n",
      "üìà Statistiques des scores FAISS :\n",
      "   Moyenne : 41.49%\n",
      "   M√©diane : 44.46%\n",
      "   Min : 18.61%\n",
      "   Max : 60.16%\n",
      "   √âcart-type : 12.51%\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# 4. ANALYSE DE LA DISTRIBUTION DES SCORES\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üìä ANALYSE DE LA DISTRIBUTION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "all_scores = [score for _, score in results_ml + results_ds + results_devops]\n",
    "\n",
    "print(f\"\\nüìà Statistiques des scores FAISS :\")\n",
    "print(f\"   Moyenne : {np.mean(all_scores):.2f}%\")\n",
    "print(f\"   M√©diane : {np.median(all_scores):.2f}%\")\n",
    "print(f\"   Min : {np.min(all_scores):.2f}%\")\n",
    "print(f\"   Max : {np.max(all_scores):.2f}%\")\n",
    "print(f\"   √âcart-type : {np.std(all_scores):.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebede924",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "üíæ SAUVEGARDE DE L'INDEX\n",
      "============================================================\n",
      "‚úÖ Index sauvegard√© : ..\\data\\faiss_index\\jobs.index\n",
      "‚úÖ Metadata sauvegard√©es : ..\\data\\faiss_index\\jobs_metadata.pkl\n",
      "\n",
      "‚úÖ Index FAISS pr√™t pour l'API !\n",
      "   Index : ..\\data\\faiss_index\\jobs.index\n",
      "   Metadata : ..\\data\\faiss_index\\jobs_metadata.pkl\n",
      "   Taille index : 75.0 KB\n",
      "   Taille metadata : 18.3 KB\n",
      "\n",
      "============================================================\n",
      "üîÑ V√âRIFICATION DU CHARGEMENT\n",
      "============================================================\n",
      "‚úÖ JobVectorStore initialis√© avec all-mpnet-base-v2 (768 dimensions)\n",
      "‚úÖ Index charg√© : 25 offres\n",
      "‚úÖ Metadata charg√©es : 25 offres\n",
      "\n",
      "‚úÖ Test de recherche apr√®s chargement :\n",
      "   #1 - Python Developer Junior (51.86%)\n",
      "   #2 - Backend Developer Python (50.07%)\n",
      "   #3 - Python Developer - Data Engineering (41.52%)\n",
      "\n",
      "üéâ Index FAISS op√©rationnel !\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# 5. SAUVEGARDE DE L'INDEX\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üíæ SAUVEGARDE DE L'INDEX\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Cr√©er le dossier de destination\n",
    "index_dir = Path('../data/faiss_index')\n",
    "index_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Chemins de sauvegarde\n",
    "index_path = index_dir / 'jobs.index'\n",
    "metadata_path = index_dir / 'jobs_metadata.pkl'\n",
    "\n",
    "# Sauvegarder\n",
    "vector_store.save(\n",
    "    index_path=str(index_path),\n",
    "    metadata_path=str(metadata_path)\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úÖ Index FAISS pr√™t pour l'API !\")\n",
    "print(f\"   Index : {index_path}\")\n",
    "print(f\"   Metadata : {metadata_path}\")\n",
    "print(f\"   Taille index : {index_path.stat().st_size / 1024:.1f} KB\")\n",
    "print(f\"   Taille metadata : {metadata_path.stat().st_size / 1024:.1f} KB\")\n",
    "\n",
    "# %%\n",
    "# 6. V√âRIFICATION DU CHARGEMENT\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üîÑ V√âRIFICATION DU CHARGEMENT\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Cr√©er un nouveau vector store\n",
    "vector_store_test = JobVectorStore(model_name='all-mpnet-base-v2')\n",
    "\n",
    "# Charger l'index\n",
    "vector_store_test.load(\n",
    "    index_path=str(index_path),\n",
    "    metadata_path=str(metadata_path)\n",
    ")\n",
    "\n",
    "# Test de recherche\n",
    "test_skills = [\"Python\", \"FastAPI\", \"Docker\"]\n",
    "test_results = vector_store_test.search(test_skills, top_k=3)\n",
    "\n",
    "print(f\"\\n‚úÖ Test de recherche apr√®s chargement :\")\n",
    "for i, (job, score) in enumerate(test_results, 1):\n",
    "    print(f\"   #{i} - {job['title']} ({score:.2f}%)\")\n",
    "\n",
    "print(\"\\nüéâ Index FAISS op√©rationnel !\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
