"""
Module de gestion du Vector Store (FAISS)
Permet de stocker et rechercher efficacement les embeddings d'offres d'emploi
"""

import faiss
import numpy as np
import json
import pickle
from pathlib import Path
from typing import List, Dict, Tuple
from sentence_transformers import SentenceTransformer


class JobVectorStore:
    """
    Gestionnaire de base vectorielle pour les offres d'emploi
    Utilise FAISS pour l'indexation et la recherche rapide
    """
    
    def __init__(self, model_name: str = "all-mpnet-base-v2"):
        """
        Initialiser le vector store
        
        Args:
            model_name: Nom du mod√®le Sentence-Transformers
        """
        self.model_name = model_name
        self.model = SentenceTransformer(model_name)
        self.dimension = self.model.get_sentence_embedding_dimension()
        self.index = None
        self.jobs_metadata = []
        self.is_trained = False
    
    def build_index(self, jobs: List[Dict]) -> None:
        """
        Construire l'index FAISS √† partir d'une liste d'offres
        
        Args:
            jobs: Liste de dictionnaires d'offres (avec 'description' minimum)
        """
        print(f"üî® Construction de l'index FAISS pour {len(jobs)} offres...")
        
        # Extraire les descriptions et m√©tadonn√©es
        descriptions = []
        self.jobs_metadata = []
        
        for job in jobs:
            # Description compl√®te pour embedding
            full_desc = f"{job['title']}. {job['description']}"
            descriptions.append(full_desc)
            
            # Sauvegarder m√©tadonn√©es (sans description pour √©conomiser RAM)
            metadata = {k: v for k, v in job.items() if k != 'description'}
            self.jobs_metadata.append(metadata)
        
        # G√©n√©rer embeddings
        print("üìä G√©n√©ration des embeddings...")
        embeddings = self.model.encode(
            descriptions,
            show_progress_bar=True,
            batch_size=32,
            convert_to_numpy=True
        )
        
        # Cr√©er index FAISS (IndexFlatIP pour similarit√© cosinus)
        print("üîß Cr√©ation de l'index FAISS...")
        self.index = faiss.IndexFlatIP(self.dimension)
        
        # Normaliser les embeddings pour cosinus similarity
        faiss.normalize_L2(embeddings)
        
        # Ajouter √† l'index
        self.index.add(embeddings)
        self.is_trained = True
        
        print(f"‚úÖ Index construit : {self.index.ntotal} offres index√©es")
    
    def search(
        self, 
        cv_text: str, 
        top_k: int = 10, 
        min_score: float = 0.0
    ) -> List[Dict]:
        """
        Rechercher les offres les plus similaires √† un CV
        
        Args:
            cv_text: Texte du CV
            top_k: Nombre de r√©sultats √† retourner
            min_score: Score minimum (0-1)
        
        Returns:
            Liste de dict {job_metadata, score}
        """
        if not self.is_trained:
            raise ValueError("‚ùå L'index n'est pas construit. Appelez build_index() d'abord.")
        
        # G√©n√©rer embedding du CV
        cv_embedding = self.model.encode([cv_text], convert_to_numpy=True)
        
        # Normaliser pour cosinus
        faiss.normalize_L2(cv_embedding)
        
        # Recherche dans FAISS
        scores, indices = self.index.search(cv_embedding, top_k)
        
        # Formater r√©sultats
        results = []
        for score, idx in zip(scores[0], indices[0]):
            # Filtrer par score minimum
            if score < min_score:
                continue
            
            # R√©cup√©rer m√©tadonn√©es
            job_meta = self.jobs_metadata[idx].copy()
            job_meta['faiss_score'] = float(score)
            job_meta['faiss_score_percent'] = float(score * 100)
            
            results.append(job_meta)
        
        return results
    
    def save(self, index_path: str, metadata_path: str) -> None:
        """
        Sauvegarder l'index et les m√©tadonn√©es sur disque
        
        Args:
            index_path: Chemin pour l'index FAISS (.index)
            metadata_path: Chemin pour les m√©tadonn√©es (.pkl)
        """
        if not self.is_trained:
            raise ValueError("‚ùå Rien √† sauvegarder, l'index n'est pas construit.")
        
        # Sauvegarder index FAISS
        faiss.write_index(self.index, index_path)
        
        # Sauvegarder m√©tadonn√©es + informations du mod√®le
        with open(metadata_path, 'wb') as f:
            pickle.dump({
                'jobs_metadata': self.jobs_metadata,
                'model_name': self.model_name,
                'dimension': self.dimension
            }, f)
        
        print(f"‚úÖ Index sauvegard√© : {index_path}")
        print(f"‚úÖ M√©tadonn√©es sauvegard√©es : {metadata_path}")
        print(f"üìå Mod√®le utilis√© : {self.model_name} ({self.dimension} dimensions)")
    
    def load(self, index_path: str, metadata_path: str) -> None:
        """
        Charger un index existant depuis le disque
        D√©tecte et charge automatiquement le bon mod√®le
        
        Args:
            index_path: Chemin de l'index FAISS
            metadata_path: Chemin des m√©tadonn√©es
        """
        # Charger m√©tadonn√©es d'abord pour conna√Ætre le mod√®le
        with open(metadata_path, 'rb') as f:
            data = pickle.load(f)
            self.jobs_metadata = data['jobs_metadata']
            saved_model_name = data.get('model_name', 'all-mpnet-base-v2')
            saved_dimension = data['dimension']
        
        # V√©rifier la compatibilit√© du mod√®le actuel
        if self.model_name != saved_model_name:
            print(f"‚ö†Ô∏è Mod√®le diff√©rent d√©tect√© !")
            print(f"   - Index sauvegard√© avec : {saved_model_name} ({saved_dimension} dim)")
            print(f"   - Mod√®le actuel : {self.model_name} ({self.dimension} dim)")
            
            # Si les dimensions ne correspondent pas, recharger le bon mod√®le
            if self.dimension != saved_dimension:
                print(f"üîÑ Chargement du mod√®le correct...")
                self.model_name = saved_model_name
                self.model = SentenceTransformer(saved_model_name)
                self.dimension = self.model.get_sentence_embedding_dimension()
                print(f"‚úÖ Mod√®le recharg√© : {self.model_name}")
            else:
                # M√™me dimensions mais diff√©rent mod√®le ‚Üí utiliser le sauvegard√©
                print(f"‚úÖ Dimensions identiques, utilisation du mod√®le sauvegard√©")
                self.model_name = saved_model_name
        
        # Charger index FAISS
        self.index = faiss.read_index(index_path)
        self.is_trained = True
        
        print(f"‚úÖ Index charg√© : {self.index.ntotal} offres")
        print(f"üìå Mod√®le final : {self.model_name} ({self.dimension} dimensions)")
    
    def get_stats(self) -> Dict:
        """Obtenir des statistiques sur le vector store"""
        if not self.is_trained:
            return {"status": "not_trained"}
        
        return {
            "status": "trained",
            "total_jobs": self.index.ntotal,
            "dimension": self.dimension,
            "model": self.model_name
        }


# ============================================================================
# FONCTIONS UTILITAIRES
# ============================================================================

def create_vector_store_from_dataset(
    jobs_json_path: str,
    output_index_path: str = "models/faiss_jobs.index",
    output_metadata_path: str = "models/faiss_jobs_metadata.pkl",
    model_name: str = "all-mpnet-base-v2"
) -> JobVectorStore:
    """
    Cr√©er et sauvegarder un vector store depuis un fichier JSON d'offres
    
    Args:
        jobs_json_path: Chemin du JSON des offres
        output_index_path: O√π sauvegarder l'index FAISS
        output_metadata_path: O√π sauvegarder les m√©tadonn√©es
        model_name: Nom du mod√®le Sentence-Transformers
    
    Returns:
        JobVectorStore entra√Æn√©
    """
    # Charger offres
    with open(jobs_json_path, 'r', encoding='utf-8') as f:
        jobs = json.load(f)
    
    print(f"üìÇ Charg√© {len(jobs)} offres depuis {jobs_json_path}")
    
    # Cr√©er vector store
    vector_store = JobVectorStore(model_name=model_name)
    
    # Construire index
    vector_store.build_index(jobs)
    
    # Sauvegarder
    Path(output_index_path).parent.mkdir(parents=True, exist_ok=True)
    vector_store.save(output_index_path, output_metadata_path)
    
    return vector_store


def load_vector_store(
    index_path: str = "models/faiss_jobs.index",
    metadata_path: str = "models/faiss_jobs_metadata.pkl",
    model_name: str = None
) -> JobVectorStore:
    """
    Charger un vector store existant
    Le mod√®le est automatiquement d√©tect√© depuis les m√©tadonn√©es
    
    Args:
        index_path: Chemin de l'index FAISS
        metadata_path: Chemin des m√©tadonn√©es
        model_name: Nom du mod√®le (optionnel, auto-d√©tect√©)
    
    Returns:
        JobVectorStore charg√©
    """
    # Si pas de mod√®le sp√©cifi√©, utiliser le d√©faut (sera corrig√© automatiquement)
    if model_name is None:
        model_name = "all-mpnet-base-v2"
    
    vector_store = JobVectorStore(model_name=model_name)
    vector_store.load(index_path, metadata_path)
    return vector_store


# ============================================================================
# TEST UNITAIRE
# ============================================================================

if __name__ == "__main__":
    """Test basique du module"""
    
    # Exemple de donn√©es
    test_jobs = [
        {
            "id": "1",
            "title": "Data Scientist",
            "description": "Python, Machine Learning, TensorFlow, PyTorch",
            "company": "TechCorp"
        },
        {
            "id": "2",
            "title": "Frontend Developer",
            "description": "React, JavaScript, HTML, CSS",
            "company": "WebAgency"
        }
    ]
    
    # Cr√©er vector store
    vs = JobVectorStore(model_name="all-mpnet-base-v2")
    vs.build_index(test_jobs)
    
    # Test recherche
    cv = "Exp√©rience en Python et Machine Learning"
    results = vs.search(cv, top_k=2)
    
    print("\nüîç R√©sultats de recherche :")
    for r in results:
        print(f"  - {r['title']} (Score: {r['faiss_score_percent']:.1f}%)")
    
    # Test sauvegarde
    import tempfile
    with tempfile.TemporaryDirectory() as tmpdir:
        idx_path = f"{tmpdir}/test.index"
        meta_path = f"{tmpdir}/test_meta.pkl"
        
        vs.save(idx_path, meta_path)
        
        # Test rechargement avec mod√®le diff√©rent
        vs2 = JobVectorStore(model_name="all-MiniLM-L6-v2")
        vs2.load(idx_path, meta_path)
        
        results2 = vs2.search(cv, top_k=2)
        print(f"\n‚úÖ Rechargement OK : {len(results2)} r√©sultats")
        print(f"üìå Mod√®le auto-corrig√© : {vs2.model_name}")
    
    print("\n‚úÖ Test r√©ussi !")